{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "7pREF3thmzrp"
      },
      "outputs": [],
      "source": [
        "idioms = \"\"\"\n",
        "      That test was a piece of cake,\n",
        "      That car cost an arm and a leg,\n",
        "      I hate going to the dentist, but I'll just have to bite the bullet,\n",
        "      I let the cat out of the bag when I told her the surprise party details,\n",
        "      A leopard can't change its spots,\n",
        "      A watched pot never boils,\n",
        "      Add fuel to the fire,\n",
        "      An ounce of prevention is worth a pound of cure,\n",
        "      At the drop of a hat,\n",
        "      Between the devil and the deep blue sea,\n",
        "      Burn the candle at both ends,\n",
        "      By the skin of one's teeth,\n",
        "      Don't bite the hand that feeds you,\n",
        "      Don't cry over spilled milk,\n",
        "      Every dog has its day,\n",
        "      Familiarity breeds contempt,\n",
        "      Get a taste of your own medicine,\n",
        "      Give someone a run for their money,\n",
        "      Go the extra mile,\n",
        "      Have a chip on your shoulder,\n",
        "      Have your cake and eat it too,\n",
        "      Hit the nail on the head,\n",
        "      If it ain't broke, don't fix it,\n",
        "      In the heat of the moment,\n",
        "      It takes two to tango,\n",
        "      Jump on the bandwagon,\n",
        "      Kill two birds with one stone,\n",
        "      Let sleeping dogs lie,\n",
        "      Make a mountain out of a molehill,\n",
        "      Mend fences before it's too late,\n",
        "      Not playing with a full deck,\n",
        "      Once bitten, twice shy,\n",
        "      Out of sight, out of mind,\n",
        "      Play with fire and you’ll get burned,\n",
        "      Put all your eggs in one basket,\n",
        "      Read between the lines,\n",
        "      Reap what you sow,\n",
        "      Slow and steady wins the race,\n",
        "      Spill the beans and ruin the surprise,\n",
        "      Steal someone’s thunder,\n",
        "      The ball is in your court,\n",
        "      The early bird catches the worm,\n",
        "      The grass is always greener on the other side,\n",
        "      The pen is mightier than the sword,\n",
        "      The proof is in the pudding,\n",
        "      There’s no such thing as a free lunch,\n",
        "      Throw caution to the wind,\n",
        "      Time flies when you're having fun,\n",
        "      Too many cooks spoil the broth,\n",
        "      Turn a blind eye to the truth,\n",
        "      Walk a mile in someone else's shoes,\n",
        "      When life gives you lemons, make lemonade,\n",
        "      Where there’s smoke, there’s fire,\n",
        "      You can’t judge a book by its cover,\n",
        "      You reap what you sow,\n",
        "      A chain is only as strong as its weakest link,\n",
        "      A penny for your thoughts,\n",
        "      Actions speak louder than words,\n",
        "      All that glitters is not gold,\n",
        "      Barking up the wrong tree,\n",
        "      Beauty is in the eye of the beholder,\n",
        "      Beggars can’t be choosers,\n",
        "      Better late than never,\n",
        "      Blood is thicker than water,\n",
        "      Curiosity killed the cat,\n",
        "      Don’t count your chickens before they hatch,\n",
        "      Don’t put all your eggs in one basket,\n",
        "      Easy come, easy go,\n",
        "      Every cloud has a silver lining,\n",
        "      Fortune favors the bold,\n",
        "      Haste makes waste,\n",
        "      Honesty is the best policy,\n",
        "      Ignorance is bliss,\n",
        "      Keep your friends close and your enemies closer,\n",
        "      Knowledge is power,\n",
        "      Laughter is the best medicine,\n",
        "      Look before you leap,\n",
        "      Money doesn’t grow on trees,\n",
        "      Necessity is the mother of invention,\n",
        "      No pain, no gain,\n",
        "      Nothing ventured, nothing gained,\n",
        "      One man’s trash is another man’s treasure,\n",
        "      Patience is a virtue,\n",
        "      Practice makes perfect,\n",
        "      Rome wasn’t built in a day,\n",
        "      Silence is golden,\n",
        "      Speak of the devil,\n",
        "      Strike while the iron is hot,\n",
        "      The best things in life are free,\n",
        "      The devil is in the details,\n",
        "      The enemy of my enemy is my friend,\n",
        "      The road to hell is paved with good intentions,\n",
        "      The squeaky wheel gets the grease,\n",
        "      There’s no place like home,\n",
        "      To each their own,\n",
        "      Tomorrow is another day,\n",
        "      Two heads are better than one,\n",
        "      What doesn’t kill you makes you stronger,\n",
        "      When in Rome, do as the Romans do,\n",
        "      Where there’s a will, there’s a way,\n",
        "      Winners never quit and quitters never win,\n",
        "      You can’t have your cake and eat it too,\n",
        "      You can’t make an omelet without breaking eggs,\n",
        "      You can lead a horse to water, but you can’t make it drink.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "VGRDUej2ry5y"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "13zW37LGr03-"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([idioms])"
      ],
      "metadata": {
        "id": "QfPO1mStsH2i"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cUuIlAFsM9h",
        "outputId": "681b07ae-851a-487a-9cf7-32626f7630d7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'a': 2,\n",
              " 'is': 3,\n",
              " 'of': 4,\n",
              " 'you': 5,\n",
              " 'your': 6,\n",
              " 'in': 7,\n",
              " 'and': 8,\n",
              " 'to': 9,\n",
              " 'it': 10,\n",
              " 'there’s': 11,\n",
              " 'on': 12,\n",
              " 'one': 13,\n",
              " 'than': 14,\n",
              " 'can’t': 15,\n",
              " 'that': 16,\n",
              " 'have': 17,\n",
              " 'out': 18,\n",
              " 'when': 19,\n",
              " 'its': 20,\n",
              " 'never': 21,\n",
              " 'too': 22,\n",
              " 'with': 23,\n",
              " 'make': 24,\n",
              " 'no': 25,\n",
              " 'as': 26,\n",
              " 'cake': 27,\n",
              " 'an': 28,\n",
              " 'i': 29,\n",
              " 'fire': 30,\n",
              " 'devil': 31,\n",
              " \"don't\": 32,\n",
              " 'day': 33,\n",
              " 'two': 34,\n",
              " 'before': 35,\n",
              " 'all': 36,\n",
              " 'eggs': 37,\n",
              " 'what': 38,\n",
              " 'makes': 39,\n",
              " 'best': 40,\n",
              " 'but': 41,\n",
              " 'bite': 42,\n",
              " 'let': 43,\n",
              " 'cat': 44,\n",
              " 'surprise': 45,\n",
              " 'details': 46,\n",
              " 'at': 47,\n",
              " 'between': 48,\n",
              " 'by': 49,\n",
              " 'every': 50,\n",
              " 'has': 51,\n",
              " 'get': 52,\n",
              " 'own': 53,\n",
              " 'medicine': 54,\n",
              " 'someone': 55,\n",
              " 'for': 56,\n",
              " 'their': 57,\n",
              " 'money': 58,\n",
              " 'go': 59,\n",
              " 'mile': 60,\n",
              " 'eat': 61,\n",
              " 'kill': 62,\n",
              " 'late': 63,\n",
              " 'not': 64,\n",
              " 'put': 65,\n",
              " 'basket': 66,\n",
              " 'reap': 67,\n",
              " 'sow': 68,\n",
              " 'free': 69,\n",
              " 'eye': 70,\n",
              " 'life': 71,\n",
              " 'where': 72,\n",
              " 'speak': 73,\n",
              " 'better': 74,\n",
              " 'water': 75,\n",
              " 'don’t': 76,\n",
              " 'easy': 77,\n",
              " 'doesn’t': 78,\n",
              " 'nothing': 79,\n",
              " 'man’s': 80,\n",
              " 'another': 81,\n",
              " 'rome': 82,\n",
              " 'are': 83,\n",
              " 'enemy': 84,\n",
              " 'my': 85,\n",
              " 'do': 86,\n",
              " 'test': 87,\n",
              " 'was': 88,\n",
              " 'piece': 89,\n",
              " 'car': 90,\n",
              " 'cost': 91,\n",
              " 'arm': 92,\n",
              " 'leg': 93,\n",
              " 'hate': 94,\n",
              " 'going': 95,\n",
              " 'dentist': 96,\n",
              " \"i'll\": 97,\n",
              " 'just': 98,\n",
              " 'bullet': 99,\n",
              " 'bag': 100,\n",
              " 'told': 101,\n",
              " 'her': 102,\n",
              " 'party': 103,\n",
              " 'leopard': 104,\n",
              " \"can't\": 105,\n",
              " 'change': 106,\n",
              " 'spots': 107,\n",
              " 'watched': 108,\n",
              " 'pot': 109,\n",
              " 'boils': 110,\n",
              " 'add': 111,\n",
              " 'fuel': 112,\n",
              " 'ounce': 113,\n",
              " 'prevention': 114,\n",
              " 'worth': 115,\n",
              " 'pound': 116,\n",
              " 'cure': 117,\n",
              " 'drop': 118,\n",
              " 'hat': 119,\n",
              " 'deep': 120,\n",
              " 'blue': 121,\n",
              " 'sea': 122,\n",
              " 'burn': 123,\n",
              " 'candle': 124,\n",
              " 'both': 125,\n",
              " 'ends': 126,\n",
              " 'skin': 127,\n",
              " \"one's\": 128,\n",
              " 'teeth': 129,\n",
              " 'hand': 130,\n",
              " 'feeds': 131,\n",
              " 'cry': 132,\n",
              " 'over': 133,\n",
              " 'spilled': 134,\n",
              " 'milk': 135,\n",
              " 'dog': 136,\n",
              " 'familiarity': 137,\n",
              " 'breeds': 138,\n",
              " 'contempt': 139,\n",
              " 'taste': 140,\n",
              " 'give': 141,\n",
              " 'run': 142,\n",
              " 'extra': 143,\n",
              " 'chip': 144,\n",
              " 'shoulder': 145,\n",
              " 'hit': 146,\n",
              " 'nail': 147,\n",
              " 'head': 148,\n",
              " 'if': 149,\n",
              " \"ain't\": 150,\n",
              " 'broke': 151,\n",
              " 'fix': 152,\n",
              " 'heat': 153,\n",
              " 'moment': 154,\n",
              " 'takes': 155,\n",
              " 'tango': 156,\n",
              " 'jump': 157,\n",
              " 'bandwagon': 158,\n",
              " 'birds': 159,\n",
              " 'stone': 160,\n",
              " 'sleeping': 161,\n",
              " 'dogs': 162,\n",
              " 'lie': 163,\n",
              " 'mountain': 164,\n",
              " 'molehill': 165,\n",
              " 'mend': 166,\n",
              " 'fences': 167,\n",
              " \"it's\": 168,\n",
              " 'playing': 169,\n",
              " 'full': 170,\n",
              " 'deck': 171,\n",
              " 'once': 172,\n",
              " 'bitten': 173,\n",
              " 'twice': 174,\n",
              " 'shy': 175,\n",
              " 'sight': 176,\n",
              " 'mind': 177,\n",
              " 'play': 178,\n",
              " 'you’ll': 179,\n",
              " 'burned': 180,\n",
              " 'read': 181,\n",
              " 'lines': 182,\n",
              " 'slow': 183,\n",
              " 'steady': 184,\n",
              " 'wins': 185,\n",
              " 'race': 186,\n",
              " 'spill': 187,\n",
              " 'beans': 188,\n",
              " 'ruin': 189,\n",
              " 'steal': 190,\n",
              " 'someone’s': 191,\n",
              " 'thunder': 192,\n",
              " 'ball': 193,\n",
              " 'court': 194,\n",
              " 'early': 195,\n",
              " 'bird': 196,\n",
              " 'catches': 197,\n",
              " 'worm': 198,\n",
              " 'grass': 199,\n",
              " 'always': 200,\n",
              " 'greener': 201,\n",
              " 'other': 202,\n",
              " 'side': 203,\n",
              " 'pen': 204,\n",
              " 'mightier': 205,\n",
              " 'sword': 206,\n",
              " 'proof': 207,\n",
              " 'pudding': 208,\n",
              " 'such': 209,\n",
              " 'thing': 210,\n",
              " 'lunch': 211,\n",
              " 'throw': 212,\n",
              " 'caution': 213,\n",
              " 'wind': 214,\n",
              " 'time': 215,\n",
              " 'flies': 216,\n",
              " \"you're\": 217,\n",
              " 'having': 218,\n",
              " 'fun': 219,\n",
              " 'many': 220,\n",
              " 'cooks': 221,\n",
              " 'spoil': 222,\n",
              " 'broth': 223,\n",
              " 'turn': 224,\n",
              " 'blind': 225,\n",
              " 'truth': 226,\n",
              " 'walk': 227,\n",
              " \"else's\": 228,\n",
              " 'shoes': 229,\n",
              " 'gives': 230,\n",
              " 'lemons': 231,\n",
              " 'lemonade': 232,\n",
              " 'smoke': 233,\n",
              " 'judge': 234,\n",
              " 'book': 235,\n",
              " 'cover': 236,\n",
              " 'chain': 237,\n",
              " 'only': 238,\n",
              " 'strong': 239,\n",
              " 'weakest': 240,\n",
              " 'link': 241,\n",
              " 'penny': 242,\n",
              " 'thoughts': 243,\n",
              " 'actions': 244,\n",
              " 'louder': 245,\n",
              " 'words': 246,\n",
              " 'glitters': 247,\n",
              " 'gold': 248,\n",
              " 'barking': 249,\n",
              " 'up': 250,\n",
              " 'wrong': 251,\n",
              " 'tree': 252,\n",
              " 'beauty': 253,\n",
              " 'beholder': 254,\n",
              " 'beggars': 255,\n",
              " 'be': 256,\n",
              " 'choosers': 257,\n",
              " 'blood': 258,\n",
              " 'thicker': 259,\n",
              " 'curiosity': 260,\n",
              " 'killed': 261,\n",
              " 'count': 262,\n",
              " 'chickens': 263,\n",
              " 'they': 264,\n",
              " 'hatch': 265,\n",
              " 'come': 266,\n",
              " 'cloud': 267,\n",
              " 'silver': 268,\n",
              " 'lining': 269,\n",
              " 'fortune': 270,\n",
              " 'favors': 271,\n",
              " 'bold': 272,\n",
              " 'haste': 273,\n",
              " 'waste': 274,\n",
              " 'honesty': 275,\n",
              " 'policy': 276,\n",
              " 'ignorance': 277,\n",
              " 'bliss': 278,\n",
              " 'keep': 279,\n",
              " 'friends': 280,\n",
              " 'close': 281,\n",
              " 'enemies': 282,\n",
              " 'closer': 283,\n",
              " 'knowledge': 284,\n",
              " 'power': 285,\n",
              " 'laughter': 286,\n",
              " 'look': 287,\n",
              " 'leap': 288,\n",
              " 'grow': 289,\n",
              " 'trees': 290,\n",
              " 'necessity': 291,\n",
              " 'mother': 292,\n",
              " 'invention': 293,\n",
              " 'pain': 294,\n",
              " 'gain': 295,\n",
              " 'ventured': 296,\n",
              " 'gained': 297,\n",
              " 'trash': 298,\n",
              " 'treasure': 299,\n",
              " 'patience': 300,\n",
              " 'virtue': 301,\n",
              " 'practice': 302,\n",
              " 'perfect': 303,\n",
              " 'wasn’t': 304,\n",
              " 'built': 305,\n",
              " 'silence': 306,\n",
              " 'golden': 307,\n",
              " 'strike': 308,\n",
              " 'while': 309,\n",
              " 'iron': 310,\n",
              " 'hot': 311,\n",
              " 'things': 312,\n",
              " 'friend': 313,\n",
              " 'road': 314,\n",
              " 'hell': 315,\n",
              " 'paved': 316,\n",
              " 'good': 317,\n",
              " 'intentions': 318,\n",
              " 'squeaky': 319,\n",
              " 'wheel': 320,\n",
              " 'gets': 321,\n",
              " 'grease': 322,\n",
              " 'place': 323,\n",
              " 'like': 324,\n",
              " 'home': 325,\n",
              " 'each': 326,\n",
              " 'tomorrow': 327,\n",
              " 'heads': 328,\n",
              " 'stronger': 329,\n",
              " 'romans': 330,\n",
              " 'will': 331,\n",
              " 'way': 332,\n",
              " 'winners': 333,\n",
              " 'quit': 334,\n",
              " 'quitters': 335,\n",
              " 'win': 336,\n",
              " 'omelet': 337,\n",
              " 'without': 338,\n",
              " 'breaking': 339,\n",
              " 'can': 340,\n",
              " 'lead': 341,\n",
              " 'horse': 342,\n",
              " 'drink': 343}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "\n",
        "\n",
        "for sentence in idioms.split('\\n'):\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range (1, len(tokenized_sentence)):\n",
        "    input_sequences.append(tokenized_sentence[:i+1])"
      ],
      "metadata": {
        "id": "mR2GD_dAsPXH"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWRQeOmnsu5l",
        "outputId": "77625c54-04d6-49a2-e43e-0bf4b15598a7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[16, 87],\n",
              " [16, 87, 88],\n",
              " [16, 87, 88, 2],\n",
              " [16, 87, 88, 2, 89],\n",
              " [16, 87, 88, 2, 89, 4],\n",
              " [16, 87, 88, 2, 89, 4, 27],\n",
              " [16, 90],\n",
              " [16, 90, 91],\n",
              " [16, 90, 91, 28],\n",
              " [16, 90, 91, 28, 92]]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = max([len(x) for x in input_sequences])"
      ],
      "metadata": {
        "id": "Jev5YsX2wC1h"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "B_FZkQeQw7NY"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences= pad_sequences(input_sequences, maxlen=max_length,padding='pre')"
      ],
      "metadata": {
        "id": "9X3VVoP1xJKP"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_input_sequences[:,:-1]"
      ],
      "metadata": {
        "id": "6ARuHOuNxQNz"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = padded_input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "EgFjTQD6pjgx"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJrxT2ervIkp",
        "outputId": "ac1009a6-316c-4c57-cd78-83f21e7b21fe"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(529, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R38bYxYWvZWw",
        "outputId": "72dd9590-44cd-4e1f-af5b-f62320fa650f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(529,)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y,num_classes= 344)"
      ],
      "metadata": {
        "id": "SbW2Fj-q40vh"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0kQSjTX5H46",
        "outputId": "58e7722d-51cc-44cc-b06a-7f43b821cfb1"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(529, 344)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ],
      "metadata": {
        "id": "chibnPP55ZEx"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=344, output_dim=100, input_length=max_length-1))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(344, activation='softmax'))"
      ],
      "metadata": {
        "id": "ov5Us-tJ6B3B"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.build(input_shape=(None, max_length-1))"
      ],
      "metadata": {
        "id": "gSj9iJU36mCQ"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "SS3pNmmZ6vfB",
        "outputId": "a83d41a1-71a9-4cbc-efd6-c0b1f54ad343"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m100\u001b[0m)             │          \u001b[38;5;34m34,400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)                 │         \u001b[38;5;34m150,600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m344\u001b[0m)                 │          \u001b[38;5;34m51,944\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">34,400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">344</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">51,944</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m236,944\u001b[0m (925.56 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">236,944</span> (925.56 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m236,944\u001b[0m (925.56 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">236,944</span> (925.56 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "37y8ssnf-WrR"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjiFCpK9KERa",
        "outputId": "a2777310-8fc4-4756-8ec9-1a7ead90e8b9"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.0566 - loss: 5.8248\n",
            "Epoch 2/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.0745 - loss: 5.4358\n",
            "Epoch 3/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.0715 - loss: 5.2558\n",
            "Epoch 4/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.0734 - loss: 5.2088\n",
            "Epoch 5/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.0825 - loss: 5.1950\n",
            "Epoch 6/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.0761 - loss: 5.2381\n",
            "Epoch 7/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.0918 - loss: 5.0215\n",
            "Epoch 8/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.0859 - loss: 5.0113\n",
            "Epoch 9/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.0763 - loss: 4.9385\n",
            "Epoch 10/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.0779 - loss: 4.8564\n",
            "Epoch 11/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.0922 - loss: 4.6563\n",
            "Epoch 12/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.1028 - loss: 4.5623\n",
            "Epoch 13/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.1164 - loss: 4.4933\n",
            "Epoch 14/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.1349 - loss: 4.3239\n",
            "Epoch 15/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.1591 - loss: 4.1641\n",
            "Epoch 16/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.2190 - loss: 3.9038\n",
            "Epoch 17/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.2069 - loss: 3.8455\n",
            "Epoch 18/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.2315 - loss: 3.7078\n",
            "Epoch 19/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.2432 - loss: 3.5390\n",
            "Epoch 20/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.3006 - loss: 3.3646\n",
            "Epoch 21/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.2988 - loss: 3.2781\n",
            "Epoch 22/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.3464 - loss: 3.0367\n",
            "Epoch 23/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.3984 - loss: 2.9471\n",
            "Epoch 24/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.4194 - loss: 2.8540\n",
            "Epoch 25/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.4090 - loss: 2.7213\n",
            "Epoch 26/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.4733 - loss: 2.6037\n",
            "Epoch 27/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5328 - loss: 2.4023\n",
            "Epoch 28/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5737 - loss: 2.3435\n",
            "Epoch 29/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.6212 - loss: 2.1222\n",
            "Epoch 30/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6189 - loss: 2.0935\n",
            "Epoch 31/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.6440 - loss: 2.0062\n",
            "Epoch 32/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.6978 - loss: 1.8305\n",
            "Epoch 33/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.7379 - loss: 1.6801\n",
            "Epoch 34/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7566 - loss: 1.6232\n",
            "Epoch 35/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7872 - loss: 1.5601\n",
            "Epoch 36/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7972 - loss: 1.4623\n",
            "Epoch 37/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8144 - loss: 1.3540\n",
            "Epoch 38/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8113 - loss: 1.3481\n",
            "Epoch 39/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8422 - loss: 1.2405\n",
            "Epoch 40/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8635 - loss: 1.1699\n",
            "Epoch 41/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8324 - loss: 1.1130\n",
            "Epoch 42/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8707 - loss: 1.0713\n",
            "Epoch 43/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8758 - loss: 1.0082\n",
            "Epoch 44/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8931 - loss: 0.9256\n",
            "Epoch 45/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8904 - loss: 0.9062\n",
            "Epoch 46/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9282 - loss: 0.7889\n",
            "Epoch 47/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9053 - loss: 0.7839\n",
            "Epoch 48/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.9175 - loss: 0.7453\n",
            "Epoch 49/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9221 - loss: 0.7320\n",
            "Epoch 50/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9187 - loss: 0.6883\n",
            "Epoch 51/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9099 - loss: 0.6406\n",
            "Epoch 52/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9228 - loss: 0.6266\n",
            "Epoch 53/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9104 - loss: 0.6336\n",
            "Epoch 54/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9239 - loss: 0.5716\n",
            "Epoch 55/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9255 - loss: 0.5279\n",
            "Epoch 56/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9265 - loss: 0.5446\n",
            "Epoch 57/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9384 - loss: 0.4895\n",
            "Epoch 58/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9436 - loss: 0.4551\n",
            "Epoch 59/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9157 - loss: 0.4778\n",
            "Epoch 60/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9449 - loss: 0.4331\n",
            "Epoch 61/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9439 - loss: 0.4194\n",
            "Epoch 62/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9573 - loss: 0.3762\n",
            "Epoch 63/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9409 - loss: 0.3978\n",
            "Epoch 64/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9397 - loss: 0.3725\n",
            "Epoch 65/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9399 - loss: 0.3748\n",
            "Epoch 66/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9505 - loss: 0.3229\n",
            "Epoch 67/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9557 - loss: 0.3245\n",
            "Epoch 68/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9322 - loss: 0.3430\n",
            "Epoch 69/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9475 - loss: 0.3246\n",
            "Epoch 70/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9528 - loss: 0.3094\n",
            "Epoch 71/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9446 - loss: 0.3089\n",
            "Epoch 72/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9505 - loss: 0.2793\n",
            "Epoch 73/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9396 - loss: 0.2941\n",
            "Epoch 74/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9370 - loss: 0.2888\n",
            "Epoch 75/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9438 - loss: 0.2679\n",
            "Epoch 76/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9402 - loss: 0.2575\n",
            "Epoch 77/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9483 - loss: 0.2544\n",
            "Epoch 78/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9545 - loss: 0.2469\n",
            "Epoch 79/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9544 - loss: 0.2407\n",
            "Epoch 80/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9547 - loss: 0.2378\n",
            "Epoch 81/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.9275 - loss: 0.2558\n",
            "Epoch 82/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.9420 - loss: 0.2214\n",
            "Epoch 83/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.9460 - loss: 0.2304\n",
            "Epoch 84/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9480 - loss: 0.2367\n",
            "Epoch 85/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9653 - loss: 0.1787\n",
            "Epoch 86/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9353 - loss: 0.2301\n",
            "Epoch 87/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9484 - loss: 0.1950\n",
            "Epoch 88/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9618 - loss: 0.1701\n",
            "Epoch 89/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9475 - loss: 0.1966\n",
            "Epoch 90/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9529 - loss: 0.1934\n",
            "Epoch 91/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9390 - loss: 0.2037\n",
            "Epoch 92/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9545 - loss: 0.1765\n",
            "Epoch 93/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9357 - loss: 0.1957\n",
            "Epoch 94/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9349 - loss: 0.1989\n",
            "Epoch 95/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9452 - loss: 0.1876\n",
            "Epoch 96/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9530 - loss: 0.1655\n",
            "Epoch 97/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9631 - loss: 0.1539\n",
            "Epoch 98/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9413 - loss: 0.1851\n",
            "Epoch 99/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9560 - loss: 0.1498\n",
            "Epoch 100/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9673 - loss: 0.1398\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b8fc9e08250>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text  = \"Patience\"\n",
        "\n",
        "\n",
        "for i in range(3):\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "\n",
        "  padded_token_input = pad_sequences([token_text],maxlen=15, padding='pre')\n",
        "  pos = np.argmax(model.predict(padded_token_input))\n",
        "\n",
        "\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == pos:\n",
        "      text = text + \" \" + word\n",
        "      print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q47kW9nsKoVa",
        "outputId": "47133b49-28ce-431b-80b3-2c5b0aeb6824"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
            "Patience is\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
            "Patience is a\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
            "Patience is a virtue\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GtGDi8MRL8HC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}